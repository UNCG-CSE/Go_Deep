{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys, os\n",
    "import traceback\n",
    "\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_data(rootdir):\n",
    "    data_list = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for fname in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + fname\n",
    "            with open(filepath) as f:\n",
    "                for line1,line2 in itertools.izip_longest(*[f]*2):\n",
    "                    try:\n",
    "                        text = ast.literal_eval(line1)\n",
    "                        label = ast.literal_eval(line2)\n",
    "                        if len(text) > 3:\n",
    "                            sentence = zip(text, label)\n",
    "                            sentence = [item for item in sentence if item[0].strip() != '']\n",
    "                            data_list.append(sentence)\n",
    "                    except:\n",
    "                        pass\n",
    "            f.close()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Intraocular', 'NA'), ('pressure', 'NA'), ('in', 'NA'), ('genetically', 'NA'), ('distinct', 'NA'), ('mice', 'NA'), ('an', 'NA'), ('update', 'NA'), ('and', 'NA'), ('strain', 'NA'), ('survey', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data('../data/')\n",
    "\n",
    "print data_list[0]\n",
    "\n",
    "train_test_cutoff = int(.70 * len(data_list)) \n",
    "training_sentences = data_list[:train_test_cutoff]\n",
    "testing_sentences = data_list[train_test_cutoff:]\n",
    " \n",
    "train_val_cutoff = int(.25 * len(training_sentences))\n",
    "validation_sentences = training_sentences[:train_val_cutoff]\n",
    "training_sentences = training_sentences[train_val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C', 'NA'), ('Diagrams', 'NA'), ('illustrating', 'NA'), ('the', 'NA'), ('structure', 'NA'), ('of', 'NA'), ('the', 'NA'), ('Tif1\\xce\\xb3predicted', 'NA'), ('peptide', 'NA'), ('and', 'NA'), ('the', 'NA'), ('three', 'NA'), ('identified', 'NA'), ('point', 'NA'), ('mutants', 'NA'), ('RING', 'NA'), ('finger', 'NA'), ('RING', 'NA'), ('Bboxes', 'NA'), ('B1', 'NA'), ('and', 'NA'), ('B2', 'NA'), ('plant', 'NA'), ('homeodomain', 'NA'), ('finger', 'NA'), ('PHD', 'NA'), ('and', 'NA'), ('bromodomain', 'NA'), ('BROMO', 'NA'), ('Numbers', 'NA'), ('below', 'NA'), ('the', 'NA'), ('first', 'NA'), ('diagram', 'NA'), ('indicate', 'NA'), ('the', 'NA'), ('percent', 'NA'), ('identity', 'NA'), ('shared', 'NA'), ('between', 'NA'), ('each', 'NA'), ('of', 'NA'), ('these', 'NA'), ('domains', 'NA'), ('in', 'NA'), ('zebrafish', 'NA'), ('and', 'NA'), ('human', 'NA'), ('TIF1\\xce\\xb3', 'NA'), ('The', 'NA'), ('predicted', 'NA'), ('truncated', 'NA'), ('proteins', 'NA'), ('are', 'NA'), ('indicated', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "print training_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_basic_features(sentence_terms, index):\n",
    "    \"\"\" Compute some very basic word features.\n",
    " \n",
    "        :param sentence_terms: [w1, w2, ...] \n",
    "        :type sentence_terms: list\n",
    "        :param index: the index of the word \n",
    "        :type index: int\n",
    "        :return: dict containing features\n",
    "        :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    term = sentence_terms[index]\n",
    "\n",
    "    return {\n",
    "        'nb_terms': len(sentence_terms),\n",
    "        'term': term,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence_terms) - 1,\n",
    "        'is_capitalized': term[0].upper() == term[0],\n",
    "        'is_all_caps': term.upper() == term,\n",
    "        'is_all_lower': term.lower() == term,\n",
    "        'prefix-1': term[0],\n",
    "        'prefix-2': term[:2],\n",
    "        'prefix-3': term[:3],\n",
    "        'suffix-1': term[-1],\n",
    "        'suffix-2': term[-2:],\n",
    "        'suffix-3': term[-3:],\n",
    "        'prev_word': '' if index == 0 else sentence_terms[index - 1],\n",
    "        'next_word': '' if index == len(sentence_terms) - 1 else sentence_terms[index + 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    \"\"\" \n",
    "    Remove the tag for each tagged term. \n",
    " \n",
    "    :param tagged_sentence: a POS tagged sentence\n",
    "    :type tagged_sentence: list\n",
    "    :return: a list of tags\n",
    "    :rtype: list of strings\n",
    "    \"\"\"\n",
    "    return [w for w, _ in tagged_sentence]\n",
    " \n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    \"\"\"\n",
    "    Split tagged sentences to X and y datasets and append some basic features.\n",
    " \n",
    "    :param tagged_sentences: a list of POS tagged sentences\n",
    "    :param tagged_sentences: list of list of tuples (term_i, tag_i)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    " \n",
    "    for pos_tags in tagged_sentences:\n",
    "        for index, (term, class_) in enumerate(pos_tags):\n",
    "            # Add basic NLP features for each sentence term\n",
    "            X.append(add_basic_features(untag(pos_tags), index))\n",
    "            y.append(class_)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_test, y_test = transform_to_dataset(testing_sentences)\n",
    "X_val, y_val = transform_to_dataset(validation_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    " \n",
    "# Fit our DictVectorizer with our set of features\n",
    "dict_vectorizer = DictVectorizer(sparse=False)\n",
    "dict_vectorizer.fit(X_train + X_test + X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert dict features to vectors\n",
    "X_train = dict_vectorizer.transform(X_train)\n",
    "X_test = dict_vectorizer.transform(X_test)\n",
    "X_val = dict_vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit LabelEncoder with our list of classes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train + y_test + y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode class values as integers\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198698, 90047) (93391, 90047) (198698, 104) (93391, 104)\n"
     ]
    }
   ],
   "source": [
    "# Convert integers to dummy variables (one hot encoded)\n",
    "from keras.utils import np_utils\n",
    " \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    " \n",
    "def build_model(input_dim, hidden_neurons, output_dim):\n",
    "    \"\"\"\n",
    "    Construct, compile and return a Keras model which will be used to fit/predict\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(hidden_neurons, input_dim=input_dim),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(hidden_neurons),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    " \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import Callback\n",
    "# from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "# import numpy as np\n",
    "\n",
    "# class Metrics(Callback):\n",
    "\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.val_f1s = []\n",
    "#         self.val_recalls = []\n",
    "#         self.val_precisions = []\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "#         val_targ = self.model.validation_data[1]\n",
    "#         _val_f1 = f1_score(val_targ, val_predict)\n",
    "#         _val_recall = recall_score(val_targ, val_predict)\n",
    "#         _val_precision = precision_score(val_targ, val_predict)\n",
    "#         self.val_f1s.append(_val_f1)\n",
    "#         self.val_recalls.append(_val_recall)\n",
    "#         self.val_precisions.append(_val_precision)\n",
    "#         print \" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall)\n",
    "#         return\n",
    "\n",
    "# metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    " \n",
    "model_params = {\n",
    "    'build_fn': build_model,\n",
    "    'input_dim': X_train.shape[1],\n",
    "    'hidden_neurons': 512,\n",
    "    'output_dim': y_train.shape[1],\n",
    "    'epochs': 5,\n",
    "    'batch_size': 256,\n",
    "    'verbose': 1,\n",
    "    'validation_data': (X_val, y_val),\n",
    "    'shuffle': True\n",
    "}\n",
    " \n",
    "clf = KerasClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hist = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
    "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
    " \n",
    "    green = '#72C29B'\n",
    "    orange = '#FFA577'\n",
    " \n",
    "    with plt.xkcd():\n",
    "        # plot model loss\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.plot(range(1, len(train_loss) + 1), train_loss, green, linewidth=5,\n",
    "                 label='training')\n",
    "        ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, orange,\n",
    "                 linewidth=5, label='validation')\n",
    "        ax1.set_xlabel('# epoch')\n",
    "        ax1.set_ylabel('loss')\n",
    "        ax1.tick_params('y')\n",
    "        ax1.legend(loc='upper right', shadow=False)\n",
    "        # plot model accuracy\n",
    "        fig, ax2 = plt.subplots()\n",
    "        ax2.plot(range(1, len(train_acc) + 1), train_acc, green, linewidth=5,\n",
    "                 label='training')\n",
    "        ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, orange,\n",
    "                 linewidth=5, label='validation')\n",
    "        ax2.set_xlabel('# epoch')\n",
    "        ax2.set_ylabel('accuracy')\n",
    "        ax2.tick_params('y')\n",
    "        ax2.legend(loc='lower right', shadow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot model performance\n",
    "plot_model_performance(\n",
    "    train_loss=hist.history.get('loss', []),\n",
    "    train_acc=hist.history.get('acc', []),\n",
    "    train_val_loss=hist.history.get('val_loss', []),\n",
    "    train_val_acc=hist.history.get('val_acc', [])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = clf.predict(X_test)\n",
    "predicted_cat = np_utils.to_categorical(predicted)\n",
    "\n",
    "# print y_test\n",
    "# print predicted_cat\n",
    "report = classification_report(y_test, predicted_cat)\n",
    "# print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
