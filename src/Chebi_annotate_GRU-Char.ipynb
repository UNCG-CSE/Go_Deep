{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys, os\n",
    "import traceback\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import progressbar\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(rootdir):\n",
    "    data_list = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for fname in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + fname\n",
    "            with open(filepath) as f:\n",
    "                for line1,line2 in itertools.izip_longest(*[f]*2):\n",
    "                    try:\n",
    "                        text = ast.literal_eval(line1)\n",
    "                        label = ast.literal_eval(line2)\n",
    "                        \n",
    "#                         for i in range(len(label)):\n",
    "#                             if label[i] == 'NA':\n",
    "#                                 label[i] = 'O'\n",
    "                        n_labels = set(label)\n",
    "                        if len(text) > 3 and len(n_labels) > 1:\n",
    "                            sentence = zip(text, label)\n",
    "                            sentence.append(('.', 'O'))\n",
    "                            sentence = [item for item in sentence if item[0].strip() != '']\n",
    "                            data_list.append(sentence)\n",
    "                    except:\n",
    "                        pass\n",
    "            f.close()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'O'), ('functional', 'O'), ('diversity', 'O'), ('of', 'O'), ('the', 'O'), ('novel', 'O'), ('conespecific', 'O'), ('genes', 'O'), ('identified', 'O'), ('here', 'O'), ('indicates', 'O'), ('molecular', 'CHEBI:23367'), ('differences', 'O'), ('between', 'O'), ('rods', 'O'), ('and', 'O'), ('cones', 'O'), ('extending', 'O'), ('far', 'O'), ('beyond', 'O'), ('those', 'O'), ('previously', 'O'), ('discovered', 'O'), ('.', 'O')]\n",
      "3127\n",
      "11109\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data('../data/input/output_chebi/')\n",
    "\n",
    "print data_list[0]\n",
    "\n",
    "# data_list = data_list[:3000]\n",
    "\n",
    "# words = list(chain.from_iterable(data_list))\n",
    "# print words\n",
    "\n",
    "print len(data_list)\n",
    "\n",
    "words = list(set(y[0] for x in data_list for y in x))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "print n_words\n",
    "\n",
    "tags = list(set(y[1] for x in data_list for y in x))\n",
    "n_tags = len(tags)\n",
    "print n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# le.fit(list(y[1] for x in data_list for y in x))\n",
    "\n",
    "# labels2idx = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# idx2la = {labels2idx[k]:k for k in labels2idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "max_len_char = 10\n",
    "\n",
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"O\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"O\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "# print word2idx['Hybrid']\n",
    "# print tag2idx[\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHEBI:32700': 1, 'CHEBI:27897': 2, 'CHEBI:16223': 3, 'CHEBI:28748': 290, 'CHEBI:23114': 6, 'CHEBI:17158': 7, 'CHEBI:32460': 8, 'CHEBI:39442': 9, 'CHEBI:26130': 10, 'CHEBI:49637': 12, 'CHEBI:22908': 13, 'CHEBI:15377': 139, 'CHEBI:25741': 14, 'CHEBI:26333': 15, 'CHEBI:32535': 266, 'CHEBI:16827': 16, 'CHEBI:22586': 17, 'CHEBI:36420': 98, 'CHEBI:22582': 72, 'CHEBI:15379': 19, 'CHEBI:34683': 20, 'CHEBI:26708': 21, 'CHEBI:22984': 22, 'CHEBI:16412': 23, 'CHEBI:24753': 24, 'CHEBI:6636': 25, 'CHEBI:23614': 26, 'CHEBI:16381': 27, 'CHEBI:23995': 28, 'CHEBI:16150': 29, 'CHEBI:24009': 213, 'CHEBI:15355': 274, 'CHEBI:32145': 33, 'CHEBI:37407': 106, 'CHEBI:16234': 35, 'CHEBI:17126': 36, 'CHEBI:16236': 37, 'CHEBI:42645': 38, 'CHEBI:24669': 291, 'CHEBI:29987': 40, 'CHEBI:22359': 41, 'CHEBI:27214': 42, 'CHEBI:41774': 43, 'CHEBI:17246': 108, 'CHEBI:22599': 45, 'CHEBI:42266': 46, 'CHEBI:30956': 47, 'CHEBI:15738': 48, 'CHEBI:28300': 49, 'CHEBI:32630': 245, 'CHEBI:22918': 50, 'CHEBI:16933': 32, 'CHEBI:15344': 53, 'CHEBI:17855': 54, 'CHEBI:15346': 175, 'CHEBI:30362': 56, 'CHEBI:42471': 57, 'CHEBI:37156': 58, 'CHEBI:8093': 59, 'CHEBI:23357': 60, 'CHEBI:30212': 279, 'CHEBI:26955': 74, 'CHEBI:25614': 286, 'CHEBI:33699': 84, 'CHEBI:36357': 183, 'CHEBI:30087': 65, 'CHEBI:33893': 66, 'CHEBI:46662': 67, 'CHEBI:24898': 68, 'CHEBI:30089': 69, 'CHEBI:37983': 70, 'CHEBI:48343': 71, 'CHEBI:35143': 73, 'CHEBI:17334': 75, 'CHEBI:27266': 76, 'CHEBI:18111': 77, 'CHEBI:7983': 78, 'CHEBI:17234': 80, 'CHEBI:33280': 81, 'CHEBI:15358': 82, 'CHEBI:27638': 83, 'CHEBI:8984': 64, 'CHEBI:17754': 226, 'CHEBI:37845': 85, 'CHEBI:46882': 86, 'CHEBI:46883': 87, 'CHEBI:24870': 88, 'CHEBI:15356': 89, 'CHEBI:16842': 90, 'CHEBI:26216': 91, 'CHEBI:33284': 228, 'CHEBI:30823': 95, 'CHEBI:17843': 96, 'CHEBI:17596': 169, 'CHEBI:33364': 62, 'CHEBI:37565': 51, 'CHEBI:5931': 100, 'CHEBI:36916': 101, 'CHEBI:46756': 102, 'CHEBI:25212': 306, 'CHEBI:44785': 103, 'CHEBI:30758': 225, 'CHEBI:22563': 105, 'CHEBI:15986': 92, 'CHEBI:27338': 280, 'CHEBI:24433': 44, 'CHEBI:32677': 185, 'CHEBI:30319': 110, 'CHEBI:35696': 111, 'CHEBI:22695': 112, 'CHEBI:22694': 113, 'CHEBI:32599': 79, 'CHEBI:48518': 94, 'CHEBI:28087': 118, 'O': 0, 'CHEBI:23240': 120, 'CHEBI:24869': 121, 'CHEBI:36080': 282, 'CHEBI:15889': 122, 'CHEBI:16113': 123, 'CHEBI:18303': 5, 'CHEBI:18291': 125, 'CHEBI:16856': 126, 'CHEBI:24621': 127, 'CHEBI:29889': 128, 'CHEBI:18295': 129, 'CHEBI:24866': 130, 'CHEBI:17737': 131, 'CHEBI:22972': 132, 'CHEBI:35780': 230, 'CHEBI:42191': 133, 'CHEBI:48561': 276, 'CHEBI:28201': 135, 'CHEBI:25016': 136, 'CHEBI:25017': 137, 'CHEBI:26833': 61, 'CHEBI:25107': 18, 'CHEBI:44658': 140, 'CHEBI:32568': 141, 'CHEBI:30756': 142, 'CHEBI:36364': 143, 'CHEBI:15858': 144, 'CHEBI:33290': 301, 'CHEBI:23888': 145, 'CHEBI:17997': 146, 'CHEBI:16750': 294, 'CHEBI:15854': 149, 'CHEBI:27570': 284, 'CHEBI:32588': 150, 'CHEBI:23019': 151, 'CHEBI:19260': 138, 'CHEBI:30808': 152, 'CHEBI:26178': 153, 'CHEBI:15347': 154, 'CHEBI:36807': 155, 'CHEBI:41237': 156, 'CHEBI:28741': 157, 'CHEBI:27363': 158, 'CHEBI:49475': 159, 'CHEBI:4911': 116, 'CHEBI:15956': 237, 'CHEBI:22925': 251, 'CHEBI:10545': 182, 'CHEBI:32952': 63, 'CHEBI:49575': 163, 'CHEBI:16865': 164, 'CHEBI:24858': 165, 'CHEBI:45536': 166, 'CHEBI:46787': 167, 'CHEBI:32958': 168, 'CHEBI:8502': 97, 'CHEBI:33708': 170, 'CHEBI:28984': 171, 'CHEBI:15033': 172, 'CHEBI:23367': 173, 'CHEBI:30687': 174, 'CHEBI:37586': 176, 'CHEBI:37585': 177, 'CHEBI:16516': 178, 'CHEBI:17996': 179, 'CHEBI:26710': 52, 'CHEBI:17992': 181, 'CHEBI:27693': 30, 'CHEBI:35406': 34, 'CHEBI:25523': 289, 'CHEBI:18421': 184, 'CHEBI:18059': 11, 'CHEBI:39015': 186, 'CHEBI:8102': 187, 'CHEBI:27594': 188, 'CHEBI:25613': 189, 'CHEBI:16199': 190, 'CHEBI:17790': 191, 'CHEBI:32835': 192, 'CHEBI:2511': 193, 'CHEBI:5032': 194, 'CHEBI:49168': 195, 'CHEBI:32441': 196, 'CHEBI:15361': 293, 'CHEBI:32861': 198, 'CHEBI:37958': 200, 'CHEBI:23243': 201, 'CHEBI:25679': 203, 'CHEBI:25939': 204, 'CHEBI:13643': 205, 'CHEBI:35195': 297, 'CHEBI:25179': 206, 'CHEBI:29019': 207, 'CHEBI:24848': 208, 'CHEBI:37926': 209, 'CHEBI:28623': 210, 'CHEBI:28619': 212, 'CHEBI:25675': 31, 'CHEBI:32139': 214, 'CHEBI:46442': 215, 'CHEBI:29021': 216, 'CHEBI:33791': 4, 'CHEBI:6495': 114, 'CHEBI:23414': 219, 'CHEBI:15428': 99, 'CHEBI:33294': 220, 'CHEBI:22977': 267, 'CHEBI:26619': 222, 'CHEBI:33567': 308, 'CHEBI:27998': 223, 'CHEBI:4056': 224, 'CHEBI:32503': 104, 'CHEBI:30616': 109, 'CHEBI:35782': 124, 'CHEBI:30751': 229, 'CHEBI:17418': 117, 'CHEBI:30757': 231, 'CHEBI:32035': 39, 'CHEBI:30755': 233, 'CHEBI:17568': 148, 'CHEBI:18320': 235, 'CHEBI:3312': 161, 'CHEBI:33839': 160, 'CHEBI:32789': 238, 'CHEBI:4883': 239, 'CHEBI:32874': 241, 'CHEBI:32875': 242, 'CHEBI:16247': 243, 'CHEBI:37396': 244, 'CHEBI:16240': 199, 'CHEBI:32648': 246, 'CHEBI:27780': 247, 'CHEBI:33521': 248, 'CHEBI:17625': 180, 'CHEBI:39026': 249, 'CHEBI:38867': 240, 'CHEBI:4917': 250, 'CHEBI:25555': 252, 'CHEBI:48706': 227, 'CHEBI:48705': 254, 'CHEBI:27026': 255, 'CHEBI:35224': 256, 'CHEBI:26714': 115, 'CHEBI:44577': 258, 'CHEBI:27902': 259, 'CHEBI:35222': 260, 'CHEBI:31624': 261, 'CHEBI:26959': 262, 'CHEBI:25435': 263, 'CHEBI:16474': 264, 'CHEBI:8040': 265, 'CHEBI:15740': 236, 'CHEBI:16761': 268, 'CHEBI:36976': 269, 'CHEBI:17478': 270, 'CHEBI:18035': 272, 'CHEBI:37527': 273, 'CHEBI:28694': 55, 'CHEBI:17578': 275, 'CHEBI:35808': 307, 'CHEBI:17632': 277, 'CHEBI:49706': 278, 'CHEBI:35225': 257, 'CHEBI:32848': 107, 'CHEBI:18248': 304, 'CHEBI:16397': 281, 'CHEBI:42098': 93, 'CHEBI:30512': 283, 'CHEBI:9754': 147, 'CHEBI:26125': 285, 'CHEBI:35211': 162, 'CHEBI:16526': 232, 'CHEBI:24849': 287, 'CHEBI:17087': 288, 'CHEBI:17387': 202, 'CHEBI:30879': 134, 'CHEBI:35456': 292, 'CHEBI:40574': 253, 'CHEBI:27641': 295, 'CHEBI:5086': 296, 'CHEBI:17076': 221, 'CHEBI:35350': 298, 'CHEBI:17748': 217, 'CHEBI:17544': 300, 'CHEBI:17939': 234, 'CHEBI:26977': 211, 'CHEBI:30779': 302, 'CHEBI:7044': 309, 'CHEBI:33250': 218, 'CHEBI:29287': 305, 'CHEBI:18245': 197, 'CHEBI:18243': 299, 'CHEBI:28112': 271, 'CHEBI:25195': 303}\n"
     ]
    }
   ],
   "source": [
    "print tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_word = [[word2idx[w[0]] for w in s] for s in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"O\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"O\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_char = []\n",
    "for sentence in data_list:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[1]] for w in s] for s in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y,value=tag2idx[\"O\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word, y, test_size=0.3, random_state=2018)\n",
    "X_char_tr, X_char_te, _, _ = train_test_split(X_char, y, test_size=0.3, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "\n",
    "# input and embedding for words\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=100,\n",
    "                     input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=100,\n",
    "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(GRU(units=100, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "main_lstm = Bidirectional(GRU(units=50, return_sequences=True,\n",
    "                               recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"sigmoid\"))(main_lstm)\n",
    "\n",
    "model = Model([word_in, char_in], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "rmsopt = RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=rmsopt, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 75, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 75, 10, 100)  10000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 75, 100)      1111100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 75, 100)      60300       time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75, 200)      0           embedding_1[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 75, 200)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 75, 100)      75300       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 75, 310)      31310       bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,010\n",
      "Trainable params: 1,288,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2188 samples, validate on 939 samples\n",
      "Epoch 1/15\n",
      "2188/2188 [==============================] - 21s 9ms/step - loss: 0.5779 - acc: 0.9367 - val_loss: 0.1960 - val_acc: 0.9672\n",
      "Epoch 2/15\n",
      "2188/2188 [==============================] - 19s 9ms/step - loss: 0.1495 - acc: 0.9742 - val_loss: 0.1120 - val_acc: 0.9817\n",
      "Epoch 3/15\n",
      " 128/2188 [>.............................] - ETA: 15s - loss: 0.0875 - acc: 0.9807"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=32, epochs=15, validation_data=([X_word_te,\n",
    "                     np.array(X_char_te).reshape((len(X_char_te), max_len, max_len_char))],\n",
    "                    np.array(y_te).reshape(len(y_te), max_len, 1)),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist.to_csv('../data/results/performance/Chebi_CHAR_GRU_Based.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"loss\"], label='Training Loss')\n",
    "plt.plot(hist[\"val_loss\"], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"acc\"], label='Training Accuracy')\n",
    "plt.plot(hist[\"val_acc\"], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model.predict([X_word_te,\n",
    "                        np.array(X_char_te).reshape((len(X_char_te),\n",
    "                                                     max_len, max_len_char))])\n",
    "true = []\n",
    "predicted_val = []\n",
    "word = []\n",
    "for i in range(len(predicted)):\n",
    "    p_tmp = np.argmax(predicted[i], axis=-1)\n",
    "    t_tmp = y_te[i]\n",
    "    word.append(X_word_te[i])\n",
    "    predicted_val.append(p_tmp)\n",
    "    true.append(t_tmp)\n",
    "\n",
    "print word[2]\n",
    "print predicted_val[2]\n",
    "print true[2]\n",
    "\n",
    "wd = [list(map(lambda x: idx2word[x], y)) for y in word]    \n",
    "p = [list(map(lambda x: idx2tag[x], y)) for y in predicted_val]\n",
    "t = [list(map(lambda x: idx2tag[x], y)) for y in true]\n",
    "\n",
    "\n",
    "print wd[2]\n",
    "print p[2]\n",
    "print t[2]\n",
    "\n",
    "report = classification_report(list(itertools.chain.from_iterable(t)), \n",
    "                                    list(itertools.chain.from_iterable(p)))\n",
    "print \"\\n\"\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 300\n",
    "pred = np.argmax(predicted[i], axis=-1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, tr, pred in zip(X_word_te[i], y_te[i], pred):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w], idx2tag[tr], idx2tag[pred]))\n",
    "\n",
    "# pd = model.predict(np.array([X_te[i]]))\n",
    "# pd = np.argmax(pd, axis=-1)\n",
    "# true = np.argmax(y_te[i], -1)\n",
    "# print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "# print(30 * \"=\")\n",
    "\n",
    "# for w, t1, pred in zip(X_te[i], true, pd[0]):\n",
    "#     if w != 0:\n",
    "#         print(\"{:15}: {:5} {}\".format(words[w-1], tags[t1], tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "{\n",
    "    'Predicted' : list(itertools.chain.from_iterable(p)),\n",
    "    'Ground Truth': list(itertools.chain.from_iterable(t)),\n",
    "    'Word' : list(itertools.chain.from_iterable(wd)),\n",
    "}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['Word'] != 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/results/Chebi_CHAR_GRU_Based.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./accuracy/src/computeSim.py ../data/results/Chebi_CHAR_GRU_Based.tsv ../data/validation_data/Chebi_AllSubsumers.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
