{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "import itertools\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "import progressbar\n",
    "from metrics.accuracy import conlleval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname):\n",
    "    text_l = []\n",
    "    label_l = []\n",
    "    with open(fname) as f:\n",
    "        for line1,line2 in itertools.izip_longest(*[f]*2):\n",
    "            try:\n",
    "                text = ast.literal_eval(line1)\n",
    "                label = ast.literal_eval(line2)\n",
    "                text_l.append(text)\n",
    "                label_l.append(label)\n",
    "            except:\n",
    "                pass\n",
    "    f.close()\n",
    "    return text_l, label_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_text, y_text = read_data('../data/11532192.txt')\n",
    "\n",
    "text = list(set(itertools.chain(*X_text)))\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(text)\n",
    "\n",
    "w2idx = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "idx2w  = {w2idx[k]:k for k in w2idx}\n",
    "\n",
    "\n",
    "X = []\n",
    "for each in X_text:\n",
    "    X.append(le.transform(each))\n",
    "    \n",
    "label = list(set(itertools.chain(*y_text)))\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(label)\n",
    "\n",
    "labels2idx = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "idx2la = {labels2idx[k]:k for k in labels2idx}\n",
    "\n",
    "y = []\n",
    "for each in y_text:\n",
    "    y.append(le.transform(each))\n",
    "\n",
    "# w2idx, labels2idx = dicts['words2idx'], dicts['labels2idx']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "words_val = [ list(map(lambda x: idx2w[x], w)) for w in X_test]\n",
    "groundtruth_val = [ list(map(lambda x: idx2la[x], y)) for y in y_test] # y values test\n",
    "words_train = [ list(map(lambda x: idx2w[x], w)) for w in X_train]\n",
    "groundtruth_train = [ list(map(lambda x: idx2la[x], y)) for y in y_train] # y values train\n",
    "\n",
    "n_classes = len(idx2la)\n",
    "n_vocab = len(idx2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence : ['In', 'strain', '129P3J', 'IOP', 'did', 'not', 'differ', 'significantly', 'with', 'age', 'between', '3', 'and', '14', 'months', 'but', 'was', 'lower', 'in', '18', 'month', 'old', 'mice', 'P', 'lt', '0001', 'compared', 'to', 'all', 'younger', 'ages', 'Figure', '4', 'Despite', 'a', '1', 'mmHg', 'dip', 'in', 'IOP', 'at', '8', 'months', 'there', 'were', 'no', 'significant', 'IOP', 'differences', 'between', 'C3HHeJ', 'mice', 'at', 'each', 'age', 'tested', 'P', '', '02', 'for', 'age', 'Although', 'the', 'effect', 'of', 'age', 'has', 'not', 'been', 'thoroughly', 'assessed', 'in', 'other', 'strains', 'no', 'obvious', 'agerelated', 'differences', 'have', 'been', 'identified', 'in', 'other', 'strains', 'analyzed', 'at', 'multiple', 'ages', 'except', 'for', 'the', 'glaucomatous', 'DBA2J', 'and', 'AKXD28Ty', 'strains']\n",
      "Encoded form: [ 227 1095   31  222  582  887  584 1073 1204  361  443   75  396   43  864\n",
      "  454 1187  815  749   54  863  907  849  280  817    3  501 1146  371 1213\n",
      "  365  203   83  182  340   12  857  590  749  222  427  114  864 1130 1192\n",
      "  883 1072  222  587  443  158  849  427  607  361 1121  280    0    6  676\n",
      "  361  133 1127  610  905  361  712  887  440 1136  419  749  919 1096  883\n",
      "  899  364  587  713  440  742  749  919 1096  393  427  869  365  637  676\n",
      " 1127  701  180  396  123 1096]\n",
      "()\n",
      "It's label : ['NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', 'NA']\n",
      "Encoded form: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example sentence : {}\".format(words_train[0]))\n",
    "print(\"Encoded form: {}\".format(X_train[0]))\n",
    "print()\n",
    "print(\"It's label : {}\".format(groundtruth_val[0]))\n",
    "print(\"Encoded form: {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 5, padding=\"same\", activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_vocab,100))\n",
    "model.add(Convolution1D(64,5,border_mode='same', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(GRU(100,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
    "model.compile('rmsprop', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 1\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 2\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 3\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 4\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 5\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 6\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 7\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  8% |######                                                                  |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         2\n",
      " GO:0005694       0.00      0.00      0.00         1\n",
      " GO:0030424       0.00      0.00      0.00         1\n",
      "         NA       1.00      1.00      1.00      3749\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3753\n",
      "\n",
      "Validating =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      " GO:0005623       0.00      0.00      0.00         1\n",
      " GO:0005694       0.00      0.00      0.00         2\n",
      "         NA       1.00      1.00      1.00      1485\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1488\n",
      "\n",
      "Epoch 8\n",
      "Training =>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% |###########################                                             |\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-be3856c49153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#some bug in keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mavgLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    931\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    932\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/somya/Virtualenvs/ml/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Training\n",
    "n_epochs = 100\n",
    "\n",
    "train_f_scores = []\n",
    "val_f_scores = []\n",
    "best_val_f1 = 0\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch {}\".format(i))\n",
    "    \n",
    "    print(\"Training =>\")\n",
    "    train_pred_label = []\n",
    "    avgLoss = 0\n",
    "\n",
    "\n",
    "    bar = progressbar.ProgressBar(maxval=len(X_train))\n",
    "    for n_batch, sent in bar(enumerate(X_train)):\n",
    "        label = y_train[n_batch]\n",
    "        label = np.eye(n_classes)[label][np.newaxis,:]\n",
    "        sent = sent[np.newaxis,:]\n",
    "\n",
    "        if sent.shape[1] > 1: #some bug in keras\n",
    "            loss = model.train_on_batch(sent, label)\n",
    "            avgLoss += loss\n",
    "\n",
    "        pred = model.predict_on_batch(sent)\n",
    "        pred = np.argmax(pred,-1)[0]\n",
    "        train_pred_label.append(pred)\n",
    "\n",
    "    avgLoss = avgLoss/n_batch\n",
    "    \n",
    "    predword_train = [ list(map(lambda x: idx2la[x], y)) for y in train_pred_label]\n",
    "    \n",
    "    \n",
    "#     con_dict = conlleval(predword_train, groundtruth_train, words_train, 'r.txt')\n",
    "#     print con_dict\n",
    "#     train_f_scores.append(con_dict['f1'])\n",
    "    \n",
    "\n",
    "    print classification_report(list(itertools.chain.from_iterable(groundtruth_train)), \n",
    "                                list(itertools.chain.from_iterable(predword_train)))\n",
    "    \n",
    "#     print('Loss = {}, Precision = {}, Recall = {}, F1 = {}'.format(avgLoss, con_dict['r'], con_dict['p'], con_dict['f1']))\n",
    "    \n",
    "    \n",
    "    print(\"Validating =>\")\n",
    "    \n",
    "    val_pred_label = []\n",
    "    avgLoss = 0\n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=len(X_test))\n",
    "    for n_batch, sent in bar(enumerate(X_test)):\n",
    "        label = y_test[n_batch]\n",
    "        label = np.eye(n_classes)[label][np.newaxis,:]\n",
    "        sent = sent[np.newaxis,:]\n",
    "        \n",
    "        if sent.shape[1] > 1: #some bug in keras\n",
    "            loss = model.test_on_batch(sent, label)\n",
    "            avgLoss += loss\n",
    "\n",
    "        pred = model.predict_on_batch(sent)\n",
    "        pred = np.argmax(pred,-1)[0]\n",
    "        val_pred_label.append(pred)\n",
    "\n",
    "    avgLoss = avgLoss/n_batch\n",
    "    \n",
    "    predword_val = [ list(map(lambda x: idx2la[x], y)) for y in val_pred_label]\n",
    "#     con_dict = conlleval(predword_val, groundtruth_val, words_val, 'r.txt')\n",
    "#     print con_dict\n",
    "#     val_f_scores.append(con_dict['f1'])\n",
    "    \n",
    "#     print('Loss = {}, Precision = {}, Recall = {}, F1 = {}'.format(avgLoss, con_dict['r'], con_dict['p'], con_dict['f1']))\n",
    "\n",
    "    print classification_report(list(itertools.chain.from_iterable(groundtruth_val)), \n",
    "                                list(itertools.chain.from_iterable(predword_val)))\n",
    "\n",
    "    \n",
    "#     if con_dict['f1'] > best_val_f1:\n",
    "#     \tbest_val_f1 = con_dict['f1']\n",
    "#     \topen('model_architecture.json','w').write(model.to_json())\n",
    "#     \tmodel.save_weights('best_model_weights.h5',overwrite=True)\n",
    "#     \tprint(\"Best validation F1 score = {}\".format(best_val_f1))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
