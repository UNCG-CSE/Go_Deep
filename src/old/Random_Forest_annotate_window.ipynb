{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, precision_recall_curve, auc, roc_curve, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import log_loss\n",
    "import itertools\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys, os\n",
    "import traceback\n",
    "from operator import itemgetter\n",
    "\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(rootdir):\n",
    "    data_list = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for fname in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + fname\n",
    "            with open(filepath) as f:\n",
    "                for line1,line2 in itertools.izip_longest(*[f]*2):\n",
    "                    try:\n",
    "                        text = ast.literal_eval(line1)\n",
    "                        label = ast.literal_eval(line2)\n",
    "                        if len(text) > 3:\n",
    "                            sentence = zip(text, label)\n",
    "                            sentence = [item for item in sentence if item[0].strip() != '']\n",
    "                            data_list.append(sentence)\n",
    "                    except:\n",
    "                        pass\n",
    "            f.close()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'NA'), ('Hybrid', 'NA'), ('Photoreceptor', 'NA'), ('Expressing', 'NA'), ('Both', 'NA'), ('Rod', 'NA'), ('and', 'NA'), ('Cone', 'NA'), ('Genes', 'NA'), ('in', 'NA'), ('a', 'NA'), ('Mouse', 'NA'), ('Model', 'NA'), ('of', 'NA'), ('Enhanced', 'NA'), ('SCone', 'NA'), ('Syndrome', 'NA')]\n",
      "5065\n",
      "[('Rod', 'NA'), ('and', 'NA'), ('cone', 'NA'), ('photoreceptors', 'NA'), ('subserve', 'NA'), ('vision', 'NA'), ('under', 'NA'), ('dim', 'NA'), ('and', 'NA'), ('bright', 'NA'), ('light', 'NA'), ('conditions', 'NA'), ('respectively', 'NA'), ('The', 'NA'), ('differences', 'NA'), ('in', 'NA'), ('their', 'NA'), ('function', 'NA'), ('are', 'NA'), ('thought', 'NA'), ('to', 'NA'), ('stem', 'NA'), ('from', 'NA'), ('their', 'NA'), ('different', 'NA'), ('gene', 'NA'), ('expression', 'NA'), ('patterns', 'NA'), ('morphologies', 'NA'), ('and', 'NA'), ('synaptic', 'GO:0045202'), ('connectivities', 'NA'), ('In', 'NA'), ('this', 'NA'), ('study', 'NA'), ('we', 'NA'), ('have', 'NA'), ('examined', 'NA'), ('the', 'NA'), ('photoreceptor', 'NA'), ('cells', 'GO:0005623'), ('of', 'NA'), ('the', 'NA'), ('retinal', 'NA'), ('degeneration', 'NA'), ('7', 'NA'), ('rd7', 'NA'), ('mutant', 'NA'), ('mouse', 'NA'), ('a', 'NA'), ('model', 'NA'), ('for', 'NA'), ('the', 'NA'), ('human', 'NA'), ('enhanced', 'NA'), ('Scone', 'NA'), ('syndrome', 'NA'), ('ESCS', 'NA'), ('This', 'NA'), ('mutant', 'NA'), ('carries', 'NA'), ('a', 'NA'), ('spontaneous', 'NA'), ('deletion', 'NA'), ('in', 'NA'), ('the', 'NA'), ('mouse', 'NA'), ('ortholog', 'NA'), ('of', 'NA'), ('NR2E3', 'NA'), ('an', 'NA'), ('orphan', 'NA'), ('nuclear', 'GO:0005634'), ('receptor', 'NA'), ('transcription', 'NA'), ('factor', 'NA'), ('mutated', 'NA'), ('in', 'NA'), ('ESCS', 'NA'), ('Employing', 'NA'), ('microarray', 'NA'), ('and', 'NA'), ('in', 'NA'), ('situ', 'NA'), ('hybridization', 'NA'), ('analysis', 'NA'), ('we', 'NA'), ('have', 'NA'), ('found', 'NA'), ('that', 'NA'), ('the', 'NA'), ('rd7', 'NA'), ('retina', 'NA'), ('contains', 'NA'), ('a', 'NA'), ('modestly', 'NA'), ('increased', 'NA'), ('number', 'NA'), ('of', 'NA'), ('Sopsin\\xe2\\x80\\x93expressing', 'NA'), ('cells', 'GO:0005623'), ('that', 'NA'), ('ultrastructurally', 'NA'), ('appear', 'NA'), ('to', 'NA'), ('be', 'NA'), ('normal', 'NA'), ('cones', 'NA'), ('Strikingly', 'NA'), ('the', 'NA'), ('majority', 'NA'), ('of', 'NA'), ('the', 'NA'), ('photoreceptors', 'NA'), ('in', 'NA'), ('the', 'NA'), ('rd7', 'NA'), ('retina', 'NA'), ('represent', 'NA'), ('a', 'NA'), ('morphologically', 'NA'), ('hybrid', 'NA'), ('cell', 'GO:0005623'), ('type', 'NA'), ('that', 'NA'), ('expresses', 'NA'), ('both', 'NA'), ('rod', 'NA'), ('and', 'NA'), ('conespecific', 'NA'), ('genes', 'NA'), ('In', 'NA'), ('addition', 'NA'), ('in', 'NA'), ('situ', 'NA'), ('hybridization', 'NA'), ('screening', 'NA'), ('of', 'NA'), ('genes', 'NA'), ('shown', 'NA'), ('to', 'NA'), ('be', 'NA'), ('upregulated', 'NA'), ('in', 'NA'), ('the', 'NA'), ('rd7', 'NA'), ('mutant', 'NA'), ('retina', 'NA'), ('by', 'NA'), ('microarray', 'NA'), ('identified', 'NA'), ('ten', 'NA'), ('new', 'NA'), ('conespecific', 'NA'), ('or', 'NA'), ('coneenriched', 'NA'), ('genes', 'NA'), ('with', 'NA'), ('a', 'NA'), ('wide', 'NA'), ('range', 'NA'), ('of', 'NA'), ('biochemical', 'NA'), ('functions', 'NA'), ('including', 'NA'), ('two', 'NA'), ('genes', 'NA'), ('specifically', 'NA'), ('involved', 'NA'), ('in', 'NA'), ('glucoseglycogen', 'NA'), ('metabolism', 'NA'), ('We', 'NA'), ('suggest', 'NA'), ('that', 'NA'), ('the', 'NA'), ('abnormal', 'NA'), ('electroretinograms', 'NA'), ('slow', 'NA'), ('retinal', 'NA'), ('degeneration', 'NA'), ('and', 'NA'), ('retinal', 'NA'), ('dysmorphology', 'NA'), ('seen', 'NA'), ('in', 'NA'), ('humans', 'NA'), ('with', 'NA'), ('ESCS', 'NA'), ('may', 'NA'), ('in', 'NA'), ('part', 'NA'), ('be', 'NA'), ('attributable', 'NA'), ('to', 'NA'), ('the', 'NA'), ('aberrant', 'NA'), ('function', 'NA'), ('of', 'NA'), ('a', 'NA'), ('hybrid', 'NA'), ('photoreceptor', 'NA'), ('cell', 'GO:0005623'), ('type', 'NA'), ('similar', 'NA'), ('to', 'NA'), ('that', 'NA'), ('identified', 'NA'), ('in', 'NA'), ('this', 'NA'), ('study', 'NA'), ('The', 'NA'), ('functional', 'NA'), ('diversity', 'NA'), ('of', 'NA'), ('the', 'NA'), ('novel', 'NA'), ('conespecific', 'NA'), ('genes', 'NA'), ('identified', 'NA'), ('here', 'NA'), ('indicates', 'NA'), ('molecular', 'NA'), ('differences', 'NA'), ('between', 'NA'), ('rods', 'NA'), ('and', 'NA'), ('cones', 'NA'), ('extending', 'NA'), ('far', 'NA'), ('beyond', 'NA'), ('those', 'NA'), ('previously', 'NA'), ('discovered', 'NA')]\n",
      "1909\n"
     ]
    }
   ],
   "source": [
    "data_list_raw = read_data('../data/input/GO/')\n",
    "\n",
    "#raw data\n",
    "print data_list_raw[0]\n",
    "print len(data_list_raw)\n",
    "\n",
    "data_list = []\n",
    "for each in data_list_raw:\n",
    "    sent = set(map(itemgetter(1), each))\n",
    "    if len(sent) != 1:\n",
    "        data_list.append(each)\n",
    "    \n",
    "#clean data\n",
    "print data_list[0]\n",
    "print len(data_list)\n",
    "\n",
    "train_test_cutoff = int(.70 * len(data_list)) \n",
    "training_sentences = data_list[:train_test_cutoff]\n",
    "testing_sentences = data_list[train_test_cutoff:]\n",
    " \n",
    "train_val_cutoff = int(.25 * len(training_sentences))\n",
    "validation_sentences = training_sentences[:train_val_cutoff]\n",
    "training_sentences = training_sentences[train_val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Horizontal', 'NA'), ('sections', 'NA'), ('of', 'NA'), ('the', 'NA'), ('indicated', 'NA'), ('genotypes', 'NA'), ('and', 'NA'), ('ages', 'NA'), ('E14', 'NA'), ('and', 'NA'), ('E16', 'NA'), ('the', 'NA'), ('period', 'NA'), ('during', 'NA'), ('which', 'NA'), ('SACs', 'NA'), ('are', 'NA'), ('born', 'NA'), ('were', 'NA'), ('stained', 'NA'), ('for', 'NA'), ('nuclei', 'GO:0005634'), ('DAPI', 'NA'), ('blue', 'NA'), ('and', 'NA'), ('either', 'NA'), ('Sphase', 'NA'), ('upper', 'NA'), ('two', 'NA'), ('panels', 'NA'), ('antiBrdU', 'NA'), ('red', 'NA'), ('or', 'NA'), ('apoptosis', 'NA'), ('lower', 'NA'), ('two', 'NA'), ('panels', 'NA'), ('TUNEL', 'NA'), ('red', 'NA'), ('In', 'NA'), ('Rb\\xe2\\x88\\x92\\xe2\\x88\\x92', 'NA'), ('retinas', 'NA'), ('BrdU', 'NA'), ('and', 'NA'), ('TUNEL', 'NA'), ('cells', 'GO:0005623'), ('can', 'NA'), ('be', 'NA'), ('seen', 'NA'), ('in', 'NA'), ('the', 'NA'), ('inner', 'NA'), ('retina', 'NA'), ('arrows', 'NA'), ('Inactivation', 'NA'), ('of', 'NA'), ('E2f1', 'NA'), ('rescued', 'NA'), ('these', 'NA'), ('defects', 'NA'), ('Scale', 'NA'), ('bar', 'NA'), ('is', 'NA'), ('50', 'NA'), ('\\xce\\xbcm', 'NA'), ('The', 'NA'), ('NBL', 'NA'), ('is', 'NA'), ('where', 'NA'), ('dividing', 'NA'), ('RPCs', 'NA'), ('are', 'NA'), ('located', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "print training_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_basic_features(sentence_terms, index):\n",
    "    \"\"\" Compute some very basic word features.\n",
    " \n",
    "        :param sentence_terms: [w1, w2, ...] \n",
    "        :type sentence_terms: list\n",
    "        :param index: the index of the word \n",
    "        :type index: int\n",
    "        :return: dict containing features\n",
    "        :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    term = sentence_terms[index]\n",
    "\n",
    "    return {\n",
    "        'nb_terms': len(sentence_terms),\n",
    "        'term': term,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence_terms) - 1,\n",
    "        'is_capitalized': term[0].upper() == term[0],\n",
    "        'is_all_caps': term.upper() == term,\n",
    "        'is_all_lower': term.lower() == term,\n",
    "        'prefix-1': term[0],\n",
    "        'prefix-2': term[:2],\n",
    "        'prefix-3': term[:3],\n",
    "        'suffix-1': term[-1],\n",
    "        'suffix-2': term[-2:],\n",
    "        'suffix-3': term[-3:],\n",
    "        'prev_word': '' if index == 0 else sentence_terms[index - 1],\n",
    "        'next_word': '' if index == len(sentence_terms) - 1 else sentence_terms[index + 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    \"\"\" \n",
    "    Remove the tag for each tagged term. \n",
    " \n",
    "    :param tagged_sentence: a POS tagged sentence\n",
    "    :type tagged_sentence: list\n",
    "    :return: a list of tags\n",
    "    :rtype: list of strings\n",
    "    \"\"\"\n",
    "    return [w for w, _ in tagged_sentence]\n",
    " \n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    \"\"\"\n",
    "    Split tagged sentences to X and y datasets and append some basic features.\n",
    " \n",
    "    :param tagged_sentences: a list of POS tagged sentences\n",
    "    :param tagged_sentences: list of list of tuples (term_i, tag_i)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    " \n",
    "    for pos_tags in tagged_sentences:\n",
    "        for index, (term, class_) in enumerate(pos_tags):\n",
    "            # Add basic NLP features for each sentence term\n",
    "            X.append(add_basic_features(untag(pos_tags), index))\n",
    "            y.append(class_)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_test, y_test = transform_to_dataset(testing_sentences)\n",
    "X_val, y_val = transform_to_dataset(validation_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    " \n",
    "# Fit our DictVectorizer with our set of features\n",
    "dict_vectorizer = DictVectorizer(sparse=False)\n",
    "dict_vectorizer.fit(X_train + X_test + X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert dict features to vectors\n",
    "X_train = dict_vectorizer.transform(X_train)\n",
    "X_test = dict_vectorizer.transform(X_test)\n",
    "X_val = dict_vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit LabelEncoder with our list of classes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train + y_test + y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode class values as integers\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107916, 63295) (63687, 63295) (107916, 104) (63687, 104)\n"
     ]
    }
   ],
   "source": [
    "# Convert integers to dummy variables (one hot encoded)\n",
    "from keras.utils import np_utils\n",
    " \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple test\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "print clf.score(X_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "scores = []\n",
    "roc_scores = []\n",
    "fprs, tprs = [], []\n",
    "\n",
    "pr_scores = []\n",
    "precisions, recalls, thresholds = [], [], []\n",
    "\n",
    "clfs = []\n",
    "\n",
    "for train, test in cv.split(X):\n",
    "    X_train, Y_train = X[train], Y[train]\n",
    "    X_test, Y_test =  X[test], Y[test]\n",
    "\n",
    "print \"Creating Classifier\"\n",
    "clf.fit(X_train, Y_train)\n",
    "print \"Classifier Complete\"\n",
    "\n",
    "train_score = clf.score(X_train, Y_train)\n",
    "test_score = clf.score(X_test, Y_test)\n",
    "\n",
    "train_errors.append(1 - train_score)\n",
    "test_errors.append(1 - test_score)\n",
    "\n",
    "scores.append(test_score)\n",
    "proba = clf.predict_proba(X_test)\n",
    "\n",
    "label_idx = 1\n",
    "fpr, tpr, roc_thresholds = roc_curve(Y_test, proba[:, label_idx])\n",
    "precision, recall, pr_thresholds = precision_recall_curve(Y_test, proba[:, label_idx])\n",
    "\n",
    "roc_scores.append(auc(fpr, tpr))\n",
    "fprs.append(fpr)\n",
    "tprs.append(tpr)\n",
    "\n",
    "pr_scores.append(auc(recall,precision))\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "thresholds.append(pr_thresholds)\n",
    "\n",
    "print(classification_report(Y_test, proba[:, label_idx] > 0.5))\n",
    "\n",
    "# get medium clone\n",
    "scores_to_sort = pr_scores  # roc_scores\n",
    "medium = np.argsort(scores_to_sort)[len(scores_to_sort) / 2]\n",
    "\n",
    "print \"Mean Accuracy: \", str(np.mean(scores))\n",
    "print \"Mean ROC Score: \", str(np.mean(roc_scores))\n",
    "print \"Mean PR Score: \", str(np.mean(pr_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
