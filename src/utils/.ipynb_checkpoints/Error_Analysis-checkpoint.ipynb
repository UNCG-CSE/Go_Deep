{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import ast\n",
    "import sys, os\n",
    "import traceback\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(rootdir):\n",
    "    data_list = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for fname in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + fname\n",
    "            with open(filepath) as f:\n",
    "                for line1,line2 in itertools.izip_longest(*[f]*2):\n",
    "                    try:\n",
    "                        text = ast.literal_eval(line1)\n",
    "                        label = ast.literal_eval(line2)\n",
    "                        n_labels = set(label)\n",
    "                        \n",
    "                        if len(text) > 3 and len(n_labels) > 1:\n",
    "                            sentence = zip(text, label)\n",
    "                            sentence.append(('.', 'O'))\n",
    "                            sentence = [item for item in sentence if item[0].strip() != '']\n",
    "                            data_list.append(sentence)\n",
    "                    except:\n",
    "                        pass\n",
    "            f.close()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 9571\n",
      "Number of Unique Words: 244792\n",
      "Number of Unique Tags: 359\n",
      "Total Number of Words: 244792\n",
      "Number of Words with Annotations: 19469\n"
     ]
    }
   ],
   "source": [
    "data_list_go = read_data('../../data/input/GO/merged/')\n",
    "words = list(set(y[0] for x in data_list_go for y in x))\n",
    "tags = list(set(y[1] for x in data_list_go for y in x))\n",
    "annot = list(y[1] for x in data_list_go for y in x if y[1] != 'O')\n",
    "twords = words = list(y[0] for x in data_list_go for y in x)\n",
    "\n",
    "print \"Number of Sentences: %d\" % len(data_list_go)\n",
    "print \"Number of Unique Words: %d\" % len(words)\n",
    "print \"Number of Unique Tags: %d\" % len(tags)\n",
    "print \"Total Number of Words: %d\" % len(twords)\n",
    "print \"Number of Words with Annotations: %d\" % len(annot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 3127\n",
      "Number of Unique Words: 86034\n",
      "Number of Unique Tags: 309\n",
      "Total Number of Words: 86034\n",
      "Number of Words with Annotations: 4567\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data('../../data/input/output_chebi/')\n",
    "words = list(set(y[0] for x in data_list for y in x))\n",
    "tags = list(set(y[1] for x in data_list for y in x))\n",
    "annot = list(y[1] for x in data_list for y in x if y[1] != 'O')\n",
    "twords = words = list(y[0] for x in data_list for y in x)\n",
    "\n",
    "print \"Number of Sentences: %d\" % len(data_list)\n",
    "print \"Number of Unique Words: %d\" % len(words)\n",
    "print \"Number of Unique Tags: %d\" % len(tags)\n",
    "print \"Total Number of Words: %d\" % len(twords)\n",
    "print \"Number of Words with Annotations: %d\" % len(annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 3042\n",
      "Number of Unique Words: 81691\n",
      "Number of Unique Tags: 68\n",
      "Total Number of Words: 81691\n",
      "Number of Words with Annotations: 4429\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data('../../data/input/output_cl/')\n",
    "tags = list(set(y[1] for x in data_list for y in x))\n",
    "annot = list(y[1] for x in data_list for y in x if y[1] != 'O')\n",
    "twords = words = list(y[0] for x in data_list for y in x)\n",
    "\n",
    "print \"Number of Sentences: %d\" % len(data_list)\n",
    "print \"Number of Unique Words: %d\" % len(words)\n",
    "print \"Number of Unique Tags: %d\" % len(tags)\n",
    "print \"Total Number of Words: %d\" % len(twords)\n",
    "print \"Number of Words with Annotations: %d\" % len(annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 5153\n",
      "Number of Unique Words: 133724\n",
      "Number of Unique Tags: 546\n",
      "Total Number of Words: 133724\n",
      "Number of Words with Annotations: 7998\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data('../../data/input/output_pr/')\n",
    "tags = list(set(y[1] for x in data_list for y in x))\n",
    "annot = list(y[1] for x in data_list for y in x if y[1] != 'O')\n",
    "twords = words = list(y[0] for x in data_list for y in x)\n",
    "\n",
    "print \"Number of Sentences: %d\" % len(data_list)\n",
    "print \"Number of Unique Words: %d\" % len(words)\n",
    "print \"Number of Unique Tags: %d\" % len(tags)\n",
    "print \"Total Number of Words: %d\" % len(twords)\n",
    "print \"Number of Words with Annotations: %d\" % len(annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 7262\n",
      "Number of Unique Words: 188416\n",
      "Number of Unique Tags: 156\n",
      "Total Number of Words: 188416\n",
      "Number of Words with Annotations: 14839\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data('../../data/input/output_so/')\n",
    "tags = list(set(y[1] for x in data_list for y in x))\n",
    "annot = list(y[1] for x in data_list for y in x if y[1] != 'O')\n",
    "twords = words = list(y[0] for x in data_list for y in x)\n",
    "\n",
    "print \"Number of Sentences: %d\" % len(data_list)\n",
    "print \"Number of Unique Words: %d\" % len(words)\n",
    "print \"Number of Unique Tags: %d\" % len(tags)\n",
    "print \"Total Number of Words: %d\" % len(twords)\n",
    "print \"Number of Words with Annotations: %d\" % len(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
